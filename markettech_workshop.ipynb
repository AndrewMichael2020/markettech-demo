{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1583fe59",
   "metadata": {},
   "source": [
    "# MarketTech: The Truth Engine\n",
    "\n",
    "Engineering data products for growth strategy.\n",
    "\n",
    "This notebook matches `markettech_workshop.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aca89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2026)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97e970",
   "metadata": {},
   "source": [
    "## Phase 1: Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Channel:\n",
    "    id: str\n",
    "    name: str\n",
    "    cac: float\n",
    "\n",
    "def generate_stream(days: int = 60, start_date: dt.date = dt.date(2025, 9, 1)) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    channels = [\n",
    "        Channel(\"CH_ORG\", \"Organic\", 0.00),\n",
    "        Channel(\"CH_SOC\", \"Paid Social\", 12.50),\n",
    "        Channel(\"CH_EML\", \"Email\", 0.50),\n",
    "    ]\n",
    "    df_chan = pd.DataFrame([c.__dict__ for c in channels])\n",
    "\n",
    "    day_idx = np.arange(days)\n",
    "    dates = np.array([start_date + dt.timedelta(days=int(i)) for i in day_idx])\n",
    "    is_weekend = np.array([d.weekday() >= 5 for d in dates], dtype=bool)\n",
    "    base = np.where(is_weekend, 1500, 800)\n",
    "    vol = np.clip(np.random.normal(loc=base, scale=100).astype(int), 300, None)\n",
    "    total_sessions = int(vol.sum())\n",
    "\n",
    "    session_id = np.random.randint(100000, 999999, size=total_sessions).astype(str)\n",
    "    day_for_session = np.repeat(np.arange(days), vol)\n",
    "    session_date = dates[day_for_session]\n",
    "\n",
    "    chan_ids = np.random.choice([\"CH_ORG\", \"CH_SOC\", \"CH_EML\"], p=[0.40, 0.40, 0.20], size=total_sessions)\n",
    "\n",
    "    hour = np.random.randint(0, 24, size=total_sessions)\n",
    "    minute = np.random.randint(0, 60, size=total_sessions)\n",
    "    second = np.random.randint(0, 60, size=total_sessions)\n",
    "\n",
    "    session_ts = np.array([dt.datetime.combine(d, dt.time(int(h), int(m), int(s)))\n",
    "                           for d, h, m, s in zip(session_date, hour, minute, second)])\n",
    "\n",
    "    engagement = np.where(\n",
    "        chan_ids == \"CH_SOC\",\n",
    "        np.clip(np.random.normal(loc=30, scale=20, size=total_sessions).astype(int), 1, None),\n",
    "        np.clip(np.random.normal(loc=120, scale=60, size=total_sessions).astype(int), 5, None),\n",
    "    )\n",
    "\n",
    "    sessions = pd.DataFrame({\n",
    "        \"event_type\": \"session_start\",\n",
    "        \"session_id\": session_id,\n",
    "        \"channel_id\": chan_ids,\n",
    "        \"ts\": pd.to_datetime(session_ts),\n",
    "        \"engagement_sec\": engagement,\n",
    "    })\n",
    "\n",
    "    base_prob = np.where(engagement > 60, 0.05, 0.005)\n",
    "    is_convert = np.random.random(size=total_sessions) < base_prob\n",
    "\n",
    "    conv_sessions = sessions.loc[is_convert, [\"session_id\", \"ts\"]].copy()\n",
    "    lag_days = np.random.randint(0, 11, size=len(conv_sessions))\n",
    "    lag_minutes = np.random.randint(5, 121, size=len(conv_sessions))\n",
    "    conv_ts = conv_sessions[\"ts\"].to_numpy() + pd.to_timedelta(lag_days, unit=\"D\") + pd.to_timedelta(lag_minutes, unit=\"m\")\n",
    "    revenue = np.round(np.random.uniform(50, 200, size=len(conv_sessions)), 2)\n",
    "\n",
    "    conversions = pd.DataFrame({\n",
    "        \"event_type\": \"purchase\",\n",
    "        \"session_id\": conv_sessions[\"session_id\"].to_numpy(),\n",
    "        \"ts\": pd.to_datetime(conv_ts),\n",
    "        \"revenue\": revenue,\n",
    "    })\n",
    "\n",
    "    return sessions, conversions, df_chan\n",
    "\n",
    "df_sess, df_conv, df_chan = generate_stream(days=60)\n",
    "print(f\"Stream Online: {len(df_sess):,} sessions | {len(df_conv):,} purchases\")\n",
    "df_sess.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d60055",
   "metadata": {},
   "source": [
    "## Phase 2: Storage (DuckDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=\":memory:\")\n",
    "con.register(\"raw_sessions\", df_sess)\n",
    "con.register(\"raw_conversions\", df_conv)\n",
    "con.register(\"dim_channels\", df_chan)\n",
    "\n",
    "con.execute(\"SELECT COUNT(*) AS sessions FROM raw_sessions\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf511654",
   "metadata": {},
   "source": [
    "## Phase 3: Metric contract (Semantic Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_semantic_view(con: duckdb.DuckDBPyConnection, window_days: int = 7) -> None:\n",
    "    window_days = int(window_days)\n",
    "    con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW f_attribution AS\n",
    "    SELECT\n",
    "        s.session_id,\n",
    "        c.name AS channel_name,\n",
    "        c.cac AS cost_per_acquisition,\n",
    "        CAST(s.ts AS TIMESTAMP) AS session_ts,\n",
    "        conv.revenue,\n",
    "        CAST(conv.ts AS TIMESTAMP) AS conversion_ts,\n",
    "        DATE_DIFF('day', CAST(s.ts AS TIMESTAMP), CAST(conv.ts AS TIMESTAMP)) AS days_to_convert,\n",
    "        CASE\n",
    "            WHEN conv.session_id IS NOT NULL\n",
    "             AND DATE_DIFF('day', CAST(s.ts AS TIMESTAMP), CAST(conv.ts AS TIMESTAMP)) <= {window_days}\n",
    "            THEN 1 ELSE 0\n",
    "        END AS is_attributed\n",
    "    FROM raw_sessions s\n",
    "    LEFT JOIN raw_conversions conv\n",
    "        ON s.session_id = conv.session_id\n",
    "    JOIN dim_channels c\n",
    "        ON s.channel_id = c.id\n",
    "    \"\"\")\n",
    "\n",
    "build_semantic_view(con, window_days=7)\n",
    "con.execute(\"SELECT * FROM f_attribution WHERE revenue IS NOT NULL LIMIT 5\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83be712",
   "metadata": {},
   "source": [
    "## Phase 4: Truth vs Fiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_summary(con: duckdb.DuckDBPyConnection) -> pd.DataFrame:\n",
    "    sql = \"\"\"\n",
    "    SELECT\n",
    "        channel_name,\n",
    "        COUNT(*) AS total_traffic,\n",
    "        COUNT(revenue) AS naive_conversions,\n",
    "        SUM(is_attributed) AS trusted_conversions,\n",
    "        COUNT(revenue) - SUM(is_attributed) AS out_of_window\n",
    "    FROM f_attribution\n",
    "    GROUP BY 1\n",
    "    ORDER BY trusted_conversions DESC\n",
    "    \"\"\"\n",
    "    return con.execute(sql).df()\n",
    "\n",
    "channel_summary(con)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd772c",
   "metadata": {},
   "source": [
    "## Phase 5: Data Quality Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quality_checks(con: duckdb.DuckDBPyConnection) -> pd.DataFrame:\n",
    "    checks = [\n",
    "        (\"Negative revenue\", \"SELECT COUNT(*) AS n FROM raw_conversions WHERE revenue < 0\"),\n",
    "        (\"Orphaned conversions\", \"\"\"\n",
    "            SELECT COUNT(*) AS n\n",
    "            FROM raw_conversions c\n",
    "            LEFT JOIN raw_sessions s ON c.session_id = s.session_id\n",
    "            WHERE s.session_id IS NULL\n",
    "        \"\"\"),\n",
    "        (\"Future session timestamps\", \"SELECT COUNT(*) AS n FROM raw_sessions WHERE CAST(ts AS TIMESTAMP) > NOW()\"),\n",
    "    ]\n",
    "\n",
    "    rows = []\n",
    "    for name, sql in checks:\n",
    "        n = int(con.execute(sql).fetchone()[0])\n",
    "        rows.append({\"check\": name, \"errors\": n, \"status\": \"PASS\" if n == 0 else \"FAIL\"})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "run_quality_checks(con)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347ecb9",
   "metadata": {},
   "source": [
    "## Phase 6: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_semantic_view(con, window_days=7)\n",
    "\n",
    "trend_sql = \"\"\"\n",
    "SELECT\n",
    "    DATE_TRUNC('week', session_ts) AS week,\n",
    "    channel_name,\n",
    "    SUM(is_attributed) AS sales\n",
    "FROM f_attribution\n",
    "GROUP BY 1, 2\n",
    "ORDER BY 1, 2\n",
    "\"\"\"\n",
    "df_viz = con.execute(trend_sql).df()\n",
    "\n",
    "pivot = df_viz.pivot(index=\"week\", columns=\"channel_name\", values=\"sales\").fillna(0)\n",
    "pivot.plot(kind=\"line\", figsize=(10, 5), title=\"Weekly Attributed Sales by Channel\")\n",
    "plt.ylabel(\"Trusted conversions (count)\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
